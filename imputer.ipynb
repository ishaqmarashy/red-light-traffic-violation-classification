{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_url = \"./data/Traffic_Violations.csv\"\n",
    "##csv_url = \"https://data.montgomerycountymd.gov/api/views/4mse-ku6q/rows.csv?accessType=DOWNLOAD\"\n",
    "df = pd.read_csv(csv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed columns that do not contribute to outcome or are incomplete\n",
    "# Some columns I removed here like longitude may make a nice visual for later\n",
    "columns_to_drop = [\n",
    "        'SeqID',\n",
    "        'HAZMAT',\n",
    "        'Search Conducted',\n",
    "        'Search Disposition',\n",
    "        'Search Outcome',\n",
    "        'Search Type',\n",
    "        'Article',\n",
    "        'Contributed To Accident',\n",
    "        'Arrest Type',\n",
    "        'Search Reason',\n",
    "        'Search Reason For Stop',\n",
    "        'Charge',\n",
    "        'Search Arrest Reason']\n",
    "\n",
    "# Drop the specified columns\n",
    "df.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n",
    "df.dropna(subset=['Description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Of Stop          0\n",
      "Year_Stop             0\n",
      "Geolocation           0\n",
      "DL State              0\n",
      "Driver State          0\n",
      "Driver City           0\n",
      "Gender                0\n",
      "Race                  0\n",
      "Violation Type        0\n",
      "Color                 0\n",
      "Model                 0\n",
      "Make                  0\n",
      "Year                  0\n",
      "VehicleType           0\n",
      "State                 0\n",
      "Month_Stop            0\n",
      "Work Zone             0\n",
      "Commercial Vehicle    0\n",
      "Commercial License    0\n",
      "Fatal                 0\n",
      "Property Damage       0\n",
      "Personal Injury       0\n",
      "Belts                 0\n",
      "Accident              0\n",
      "Longitude             0\n",
      "Latitude              0\n",
      "Description           0\n",
      "SubAgency             0\n",
      "Agency                0\n",
      "Time Of Stop          0\n",
      "Alcohol               0\n",
      "Day_Stop              0\n",
      "Location              4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "categorical_cols = ['VehicleType', 'Make', 'Model', 'Color', 'State', 'Driver State', 'DL State', 'Driver City']\n",
    "\n",
    "df['Date Of Stop'] = pd.to_datetime(df['Date Of Stop'])\n",
    "df['Year_Stop'] = df['Date Of Stop'].dt.year\n",
    "df['Month_Stop'] = df['Date Of Stop'].dt.month\n",
    "df['Day_Stop'] = df['Date Of Stop'].dt.day\n",
    "\n",
    "year_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "df['Year'] = year_imputer.fit_transform(df[['Year']])\n",
    "\n",
    "for col in categorical_cols:\n",
    "    most_frequent_value = df[col].mode()[0]  \n",
    "    df[col].fillna(most_frequent_value, inplace=True)\n",
    "\n",
    "missing_values = df.isna().sum().sort_values()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1879902 entries, 0 to 1879911\n",
      "Data columns (total 33 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   Date Of Stop        datetime64[ns]\n",
      " 1   Time Of Stop        object        \n",
      " 2   Agency              object        \n",
      " 3   SubAgency           object        \n",
      " 4   Description         object        \n",
      " 5   Location            object        \n",
      " 6   Latitude            float64       \n",
      " 7   Longitude           float64       \n",
      " 8   Accident            object        \n",
      " 9   Belts               object        \n",
      " 10  Personal Injury     object        \n",
      " 11  Property Damage     object        \n",
      " 12  Fatal               object        \n",
      " 13  Commercial License  object        \n",
      " 14  Commercial Vehicle  object        \n",
      " 15  Alcohol             object        \n",
      " 16  Work Zone           object        \n",
      " 17  State               object        \n",
      " 18  VehicleType         object        \n",
      " 19  Year                float64       \n",
      " 20  Make                object        \n",
      " 21  Model               object        \n",
      " 22  Color               object        \n",
      " 23  Violation Type      object        \n",
      " 24  Race                object        \n",
      " 25  Gender              object        \n",
      " 26  Driver City         object        \n",
      " 27  Driver State        object        \n",
      " 28  DL State            object        \n",
      " 29  Geolocation         object        \n",
      " 30  Year_Stop           int32         \n",
      " 31  Month_Stop          int32         \n",
      " 32  Day_Stop            int32         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(3), object(26)\n",
      "memory usage: 466.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishaq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    tokens = text.lower().translate(translator).split()\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df['Description'] = df['Description'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date Of Stop', 'Time Of Stop', 'Agency', 'SubAgency', 'Description',\n",
       "       'Location', 'Latitude', 'Longitude', 'Accident', 'Belts',\n",
       "       'Personal Injury', 'Property Damage', 'Fatal', 'Commercial License',\n",
       "       'Commercial Vehicle', 'Alcohol', 'Work Zone', 'State', 'VehicleType',\n",
       "       'Year', 'Make', 'Model', 'Color', 'Violation Type', 'Race', 'Gender',\n",
       "       'Driver City', 'Driver State', 'DL State', 'Geolocation', 'Year_Stop',\n",
       "       'Month_Stop', 'Day_Stop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/Traffic_Violations_Imputed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
